{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentence embedding - från start till bert\n",
    "<img src='images/bert-ernie-sesame-street.jpg' style='width:800px'/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kort om utvecklingen inom NLP\n",
    "* Word2vec – embeddings\n",
    "    * fastText och GloVe\n",
    "    * doc2vec\n",
    "\n",
    "        \n",
    "* seq2seq neurala nätverk\n",
    "    * Encoder-decoder nätverk\n",
    "    * Attention\n",
    "    * Transformer model\n",
    "    * BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### word2vec \n",
    "https://arxiv.org/abs/1301.3781\n",
    "\n",
    "Representera ord utifrån vilka ord som används i samma sammanhang\n",
    "\n",
    "”show me your friends, and I'll tell who you are”\n",
    "\n",
    "<img src='images/word2vec.png' style='width:600px'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fastText och GloVe\n",
    "\n",
    "* Användbara paket för träning av word2vec modeller\n",
    "* Har förtränade modeller på olika språk\n",
    "<img src='images/fasttext.png' style='width:400px'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### setup fastText\n",
    "```bash\n",
    "\n",
    "%%bash \n",
    "pip install -U tensorflow==1.14.0 gensim==3.8.0 fasttext==0.9.1 keras==2.2.5\n",
    "\n",
    "wget 'https://dl.fbaipublicfiles.com/fasttext/vectors-english/wiki-news-300d-1M.vec.zip'\n",
    "mkdir fasttext \n",
    "unzip 'wiki-news-300d-1M.vec.zip' -d fasttext\n",
    "rm 'wiki-news-300d-1M.vec.zip'\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def cosine_sim(s1, s2):\n",
    "    return np.dot(s1,s2)/(np.linalg.norm(s1)*np.linalg.norm(s2)+1e-9)\n",
    "\n",
    "\n",
    "def get_fasttext_wv(word, model, vec_len=300):\n",
    "    return model.get(word, np.zeros(vec_len))\n",
    "   \n",
    "\n",
    "\n",
    "def fasttext_doc2vec(string, model, stop_words=list(), weights=dict(), smoothing_factor=1, n_dim=300):\n",
    "    \"\"\"\n",
    "    sentence embedding from a word embedding model and string sentence. \n",
    "    args:\n",
    "    string(str): the string to be embedded\n",
    "    model(gensim.models.keyedvectors.Word2VecKeyedVectors): the model\n",
    "    stop_words(list): optional stop words to be removed\n",
    "    weights(dict): optional dict with weights of words \n",
    "    smoothing_factor(int): helps smoothing the doc2 vec. A nonzero value is as \n",
    "    if all words without an explicit weight would have that value as explict. A smoothing factor=0 \n",
    "    is equivalent to ignoring words that has no explcit weight. Set to 1 if unsure.\n",
    "    \n",
    "    \"\"\"\n",
    "    words = set(re.findall(\"[\\w\\d'-]+\", string.lower())) # ignores multiple uses of a word in the doc\n",
    "    \n",
    "    word_weights = []\n",
    "    if words:\n",
    "        word_vectors = [get_fasttext_wv(word, model) for word in words if word not in stop_words]\n",
    "        for word in words:\n",
    "            try:\n",
    "                word_weights.append(weights[word])\n",
    "            except:\n",
    "                word_weights.append(smoothing_factor)\n",
    "                \n",
    "        se = np.mean([vec / (np.linalg.norm(vec) + 1e-9) * weight for vec, weight in zip(word_vectors, word_weights)], axis = 0)\n",
    "    else:\n",
    "        print('Zero doc2vec vector for: ' + string)\n",
    "        se = np.zeros(n_dim)\n",
    "    return se  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "import re\n",
    "import numpy as np\n",
    "filename = 'fasttext/wiki-news-300d-1M.vec'\n",
    "fasttext_model = KeyedVectors.load_word2vec_format(filename)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document similarity between \n",
      "\n",
      "(1) What is your favourite hobby?\n",
      "(2) Wat do you really like to do in your spare time?\n",
      "is: 0.8130461087004068\n"
     ]
    }
   ],
   "source": [
    "## text att jämföra\n",
    "string_1 = 'What is your favourite hobby?'\n",
    "string_2 = 'Wat do you really like to do in your spare time?'\n",
    "\n",
    "\n",
    "str_1_emb = fasttext_doc2vec(string_1, fasttext_model)\n",
    "str_2_emb = fasttext_doc2vec(string_2, fasttext_model)\n",
    "\n",
    "s1_s2_sim_fasttext = cosine_sim(str_1_emb, str_2_emb)\n",
    "\n",
    "print('Document similarity between \\n\\n(1) {s1}\\n(2) {s2}\\nis: {sim}'.format(s1=string_1,\n",
    "                                                                       s2=string_2,\n",
    "                                                                       sim=s1_s2_sim_fasttext))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Träna word2vec på IMDB dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "\n",
    "%%bash\n",
    "wget http://wmz.gp/0tIo\n",
    "mkdir imdb \n",
    "unzip '0tIo' -d imdb\n",
    "rm '0tIo'\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import os\n",
    "import numpy as np\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "\n",
    "\n",
    "def load_raw_imdb(imdb_dir = '/home/gurra/code/private/bert/imdb', data_type='train'):\n",
    "    train_dir = os.path.join(imdb_dir, data_type)\n",
    "\n",
    "    labels = []\n",
    "    texts = []\n",
    "\n",
    "    for label_type in ['neg', 'pos']:\n",
    "        dir_name = os.path.join(train_dir, label_type)\n",
    "        for fname in os.listdir(dir_name):\n",
    "            if fname[-4:] == '.txt':\n",
    "                f = open(os.path.join(dir_name, fname))\n",
    "                texts.append(f.read())\n",
    "                f.close()\n",
    "                if label_type == 'neg':\n",
    "                    labels.append(0)\n",
    "                else:\n",
    "                    labels.append(1)\n",
    "    return texts, labels\n",
    "\n",
    "def make_simple_model(input_dim):       \n",
    "    model = Sequential()\n",
    "    model.add(Dense(100, input_dim=input_dim))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(rate=0.5))\n",
    "    \n",
    "    model.add(Dense(100))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(rate=0.5))\n",
    "    \n",
    "    model.add(Dense(50))\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    model.add(Dense(1))\n",
    "    model.add(Activation('sigmoid'))\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def compile_and_train(model, X_train, y_train):\n",
    "    optimizer = optimizers.RMSprop(lr=0.0003, rho=0.9, epsilon=None, decay=0.001)\n",
    "    model.compile(optimizer=optimizer, \n",
    "                   loss='binary_crossentropy', \n",
    "                   metrics=['accuracy'])\n",
    "\n",
    "    hist = model.fit(X_train, y_train, epochs=100, batch_size=512, validation_split=0.1, shuffle=True, verbose = 0)\n",
    "    print('Best validation accuracy: %.3f ' % max(w1v_hist.history['val_acc']))\n",
    "    return model, hist\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "train_texts, y_train = load_raw_imdb(data_type='train')\n",
    "X_train = np.asarray([fasttext_doc2vec(sent, fasttext_model) for sent in train_texts])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2264"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_texts[400])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best validation accuracy: 0.868 \n"
     ]
    }
   ],
   "source": [
    "word2vec_model = make_simple_model(X_train.shape[1])\n",
    "w2v_mod, _ = compile_and_train(word2vec_model, X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## doc2vec\n",
    "* Inte helt lätt att skapa representationer av hela meningar/dokument\n",
    "* BoW\n",
    "* Viktade medelvektorer\n",
    "* Doc2VecC - https://arxiv.org/pdf/1707.02377.pdf\n",
    "* WMD - http://proceedings.mlr.press/v37/kusnerb15.pdf\n",
    "* Svårt att hantera ordning på ord och homonymer (banan, rabatt, springa)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## seq2seq\n",
    "* RNN till RNN \n",
    "* Två moduler – Encoder och decoder\n",
    "<img src='images/encdec.gif' style='width:600px'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoder-decoder network\n",
    "<img src='images/enc-dec network.PNG' style='width:1000px'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder-decoder network  med attention\n",
    "<img src='images/attention layer.PNG' style='width:1000px'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attention is all you need – Transformers \n",
    "> https://arxiv.org/abs/1706.03762 \n",
    "\n",
    "> http://jalammar.github.io/illustrated-transformer/\n",
    "\n",
    "\n",
    "<img src='images/the_transformer_3.png' style='width:1000px'/>\n",
    "<img src='images/transformer_4.png' style='width:500px'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformer multi-head attention\n",
    "\n",
    "<img src='images/transform20fps.gif' style='width:400px'/>\n",
    "\n",
    "* Inga RNN-moduler --> enklare parallellisering \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BERT \n",
    "> \"Bidirectional Encoder Representations from Transformers\"\n",
    "\n",
    "Fokus på representationerna från encoder-delen ≈ doc2vec\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "%%bash \n",
    "pip install bert-serving-server==1.9.6 bert-serving-client==1.9.6\n",
    "wget 'https://storage.googleapis.com/bert_models/2018_10_18/uncased_L-12_H-768_A-12.zip'\n",
    "mkdir bert \n",
    "unzip 'uncased_L-12_H-768_A-12.zip' -d bert\n",
    "rm 'uncased_L-12_H-768_A-12.zip'\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### starta bert-server (i separat terminal)\n",
    "```bash\n",
    "bert-serving-start -model_dir '/home/gurra/coding/bert/bert_tutorial/bert/uncased_L-12_H-768_A-12' -num_worker=1 \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bert_serving.client import BertClient\n",
    "bc=BertClient(check_length=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document similarity between \n",
      "\n",
      "(1)What is your favourite hobby?\n",
      "(2)Wat do you really like to do in your spare time?\n",
      "is: 0.8376640451937843\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "s1 = bc.encode([string_1])\n",
    "s2 = bc.encode([string_2])\n",
    "s1_s2_sim_bert = cosine_sim(s1[0],s2[0])\n",
    "\n",
    "print('Document similarity between \\n\\n(1){s1}\\n(2){s2}\\nis: {sim}'.format(s1=string_1,\n",
    "                                                                       s2=string_2,\n",
    "                                                                       sim=s1_s2_sim_bert))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gurra/code/private/bert/env/lib/python3.6/site-packages/bert_serving/client/__init__.py:299: UserWarning: some of your sentences have more tokens than \"max_seq_len=256\" set on the server, as consequence you may get less-accurate or truncated embeddings.\n",
      "here is what you can do:\n",
      "- disable the length-check by create a new \"BertClient(check_length=False)\" when you do not want to display this warning\n",
      "- or, start a new server with a larger \"max_seq_len\"\n",
      "  '- or, start a new server with a larger \"max_seq_len\"' % self.length_limit)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-108-065aaab3936b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtrain_texts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_raw_imdb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mX_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_texts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/code/private/bert/env/lib/python3.6/site-packages/bert_serving/client/__init__.py\u001b[0m in \u001b[0;36marg_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    204\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreceiver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetsockopt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzmq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRCVTIMEO\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mzmq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAgain\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_e\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m                 t_e = TimeoutError(\n",
      "\u001b[0;32m~/code/private/bert/env/lib/python3.6/site-packages/bert_serving/client/__init__.py\u001b[0m in \u001b[0;36mencode\u001b[0;34m(self, texts, blocking, is_tokenized, show_tokens)\u001b[0m\n\u001b[1;32m    302\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mblocking\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 304\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recv_ndarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    305\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoken_info_available\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mshow_tokens\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/private/bert/env/lib/python3.6/site-packages/bert_serving/client/__init__.py\u001b[0m in \u001b[0;36m_recv_ndarray\u001b[0;34m(self, wait_for_req_id)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_recv_ndarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwait_for_req_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m         \u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwait_for_req_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m         \u001b[0marr_info\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marr_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjsonapi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrombuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_buffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'dtype'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/private/bert/env/lib/python3.6/site-packages/bert_serving/client/__init__.py\u001b[0m in \u001b[0;36m_recv\u001b[0;34m(self, wait_for_req_id)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m                 \u001b[0;31m# receive a response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m                 \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreceiver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_multipart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m                 \u001b[0mrequest_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/private/bert/env/lib/python3.6/site-packages/zmq/sugar/socket.py\u001b[0m in \u001b[0;36mrecv_multipart\u001b[0;34m(self, flags, copy, track)\u001b[0m\n\u001b[1;32m    473\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0many\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreasons\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mSocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mmight\u001b[0m \u001b[0mfail\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m         \"\"\"\n\u001b[0;32m--> 475\u001b[0;31m         \u001b[0mparts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m         \u001b[0;31m# have first part already, only loop while more to receive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetsockopt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzmq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRCVMORE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket._recv_copy\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/code/private/bert/env/lib/python3.6/site-packages/zmq/backend/cython/checkrc.pxd\u001b[0m in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_texts, y_train = load_raw_imdb(data_type='train')\n",
    "X_train = bc.encode(train_texts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_model = make_simple_model(X_train.shape[1])\n",
    "bert_mod, _ = compile_and_train(bert_model, X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vidare forskning\n",
    "\n",
    "* XLnet - https://mlexplained.com/2019/06/30/paper-dissected-xlnet-generalized-autoregressive-pretraining-for-language-understanding-explained/\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 768)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
